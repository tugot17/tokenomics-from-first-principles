{
  "metadata": {
    "timestamp": "2025-03-21T19:03:58.319911",
    "model": "llama-3.3-70bb",
    "dataset_key": "dummy_7001",
    "api_base": "http://localhost:8000/v1",
    "batch_sizes": [
      1,
      2,
      4,
      8
    ],
    "num_runs": 1,
    "max_tokens": 100,
    "temperature": 0.5,
    "seed": 42,
    "description": "LLama 3.3 TP4, no spec dec"
  },
  "results": {
    "1": {
      "avg_input_tokens": 7036.0,
      "avg_output_tokens": 100.0,
      "elapsed_time": 2.4206477110274136,
      "tokens_per_second_in_batch": 41.31125712529076,
      "avg_tokens_per_second": 41.31766733517994
    },
    "2": {
      "avg_input_tokens": 7036.0,
      "avg_output_tokens": 100.0,
      "elapsed_time": 3.0594187858514488,
      "tokens_per_second_in_batch": 65.37189381359543,
      "avg_tokens_per_second": 33.0089638082482
    },
    "4": {
      "avg_input_tokens": 7036.0,
      "avg_output_tokens": 100.0,
      "elapsed_time": 4.455322375986725,
      "tokens_per_second_in_batch": 89.78025970823526,
      "avg_tokens_per_second": 22.984067661164328
    },
    "8": {
      "avg_input_tokens": 7036.0,
      "avg_output_tokens": 100.0,
      "elapsed_time": 7.325049971230328,
      "tokens_per_second_in_batch": 109.21427200388513,
      "avg_tokens_per_second": 14.185198604298524
    }
  }
}